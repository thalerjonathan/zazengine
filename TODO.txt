Transparency-Rendering (see GPU Gems 2 Page 295)
	-> Render Lighting-Stage output to G-Buffer Color-Attachment 4
		-> bypass all when there are no transparent objects visible/available
			-> render opaque-stuff directly to screen
	
	-> Render transparent object
		-> copy depth from g-buffer to intermediate-depth FBO
			-> the reason for this is because we need to access the background-depth (as stored in g-buffer) but will write to it in same process when rendering the transparent object
				=> we cannot write to an already bound render-target (depth will be bound as sampler) so we need to copy it and bind it to another texture
			-> during first implementation, ignore this detail, no reading from depth yet
		-> read backgroundColor from Color-Attachment 4
			-> it was written beforehand by lighting-passes
		-> write output to Color-Attachment 1
			-> final_color = inputColor * inputAlpha + backgroundColor * ( 1.0 - inputAlpha );
			-> final_color.a = 0.0; // needed to mark pixels as transparent for later finalize-step
		-> simulate refraction (see GPU Gems 1)
			-> everything happens in screen-space!
			-> take normal from geometry or lookup from normal-map
			-> need screenspace-position in NDC [ -1 to 1 ] for fragment
			-> calculate perturbed texture-coordinate for lookup into background
					-> vec2 pertTexCoord = ( ( screenSpacePos.xy + normal.xy ) + 2.0 ) * 0.25;
						-> needs to be transformed either in range 0.0 - 1.0 for texture lookup ( => ... + 2.0 ) * 0.25;
						-> or set texture-parameter from GL_GLAMP to GL_REPEAT but this could cause things to show up repated in refraction when using extreme geometry
		-> simulate chromatic abberration (see Orange Book)
			-> need to simulate different wavelengths for red, green and blue channels
		-> prevent artifacts on edges by checking pertubed fragment depth by reading depth from intermediate-depth fbo depth

	-> Render transparency behind transparency - high performance penalty!
		-> after first object Color-Attachment 1 contains all affected fragments with transparent-color with alpha 0.0 and others black with alpha 1.0
		-> Color-Attachment 4 still contains Background
		-> do combining step to Color-Target 2 ( performance: only if there is next object and next object is behind previous object AND intersects in screen-space )
			-> read from Color-Attachment 4 as Background
			-> read from Color-Attachment 1 as Transparency-Intermediate
			-> write to Color-Attachment 2 as new Background
			-> render full-screen quad & run shader
				-> in Color-Attachment 2 all affected pixel have transparency of 0.0
				-> apply combination
					-> final_color = opaqueColor * transpColor.a + transpColor;
					-> final_color.a = 1.0;
		-> now Color-Attachment 2 becomes the new Background
		-> Color-Attachment 1 will still serve as Transparency-Intermediate
		-> Color-Attachment 4 will be used for the next final combination
			=> background ping-pongs always between target 2 and target 4
		-> proceed with next transparent object
		
	-> final output to default will happen when last transparent object is rendered, then combination will be done to default-framebuffer instead of g-buffer attachment
	
	-> Do Colored Shadow-Rendering for Transparent objects
		-> render transparent object in shadow-map generation AND write color of transparent object to additional color-texture in shadow-fbo
			-> optimization: when material is transparent write to 1.0 to alpha-channel, else 0.0
			=> need additional render-target in shadow-fbo: shadow-color target
		-> during light-rendering: when fragment in shadow do an additional lookup into the shadow-color texture to get the shadow-color for this fragment
			-> optimization: only do additional lookup when alpha-channel is 1.0
		-> for better quality: do multisampling texture lookups
	
Reflections
	-> environment (cube-mapping)
		-> need very generic renderFrame-method which allows to be called recursively
			-> need for every recursion level one CubeMap-FBO
			-> need to generify much of the code of the renderer-loop
			-> pass in some render-Context struct 
				-> holds recursion-level
				-> holds render-target where to render or null when to default framebuffer
				-> holds flag if shadow-rendering in environment-rendering
				-> holds flag if transparency-rendering in environment-rendering
				-> holds flag if interreflection-rendering in environment-rendering
				-> holds max recursion depth
		-> can be done directly with deferred renderning, no need for fallback to forward-rendering
			-> but need additional environment-rendering fbo
				-> render 6 faces of a cubemap, each with deferred rendering => fucking huge impact on bandwith and performance
					-> dramatic reduced resolution of cube-map sides e.g. 512x512
		-> http://stackoverflow.com/questions/9841863/reflection-refraction-with-chromatic-aberration-eye-correction
		-> can to do refraction & reflection
		-> different texture-binding because material could or could not use binding points
		-> more flexible renderInstances: need finer control over which materials to draw
		-> new material-type:
			<material name="Glass">
				<type id="ENVIRONMENTAL">
				  <reflection>
					... params
				  </reflection>

				  <refraction>
					... params
				  </refraction>
      
				  <diffuseColor file="cross_diffuse.jpg"/>
				  <color r="0.54" g="0.89" b="0.63"/>
				</type>
			  </material>
	-> planar (?)

	
Multiple lights
	-> blending 
	-> use stencil buffer to reduce lighting to geometry only
		-> use only for point- & spotlight because directional light will affect sky-box and ambient too
	-> correct lighting-equations: falloff, cone, ...
		-> point-light
	-> Solve Problem of Ambient + Sky-Box Lighting
		-> when no directional light in scene
			-> render full-screen quad and apply ambient-term to non-sky-box material and diffuse-only to sky-box material => need new program
			-> other lights accumulate by blending
		-> when directional light in scene
			-> include ambient-term in non-sky-box material and diffuse-only to sky-box material 
	->  bounding geometry for light
		-> point-light: sphere with radius 1 and then scale according to light distance & some epsilon
			-> low-poly count
		-> spot-light: ?
	
Mip-Map Creation in TextureFactory
			
Normal-mapping
	-> need to transform view-space normal of the object instead of transforming the viewing-direction and the light-direction to tangent-space
		-> why? because we have no more access to each tangent&bitangent in the lighting-pass and storing them in additional render-targets would be by far too much of overhead
		=> do it in geometry-stage fragment-shader
		
Shadow-mapping
	-> shadow-mapping of point-light
	-> do some sampling on shadow-edges
		-> multisampling
				
Msaa
	-> do sampling in geometry fragment-shader (centroid)
	-> dual source blending?
	
Instanced Rendering
	-> high number of meshes rendering
	
Text-rendering
	-> use OGLFT
	
Do Culling
	-> View-Frustum
	-> Occlusion Culling using queries (like CHC++) 
	-> Culling library (Umbra 3) ?
	
Need generic effect/material functionality
	-> no need to set input or output indices in shaders, can be done with layout ( location = ... ) 
	-> on top of program- & shader-management
		-> implement #include in shaders: parse loaded string and replace
		-> problem: compiler error generate other line numbers!
	-> use shaders-subroutines
		-> compile all possible material stuff in the shader and select by setting propriate subroutine
			-> needs includes
	-> based upon effect-files like directx/cg shader effects
	-> need some semantics on uniforms
	-> custom shader program for material programming
	-> problem: shaders-effect architecture from 2003 is based upon forward-rendering, we need now to plug it into deferred rendering
		-> 2 stages: geometry & ligting => potential up to 4 shaders/material: vertex&fragment in geometry & lighting
			-> BUT: vertex in geometry- & lighting-stage is very hard wired to deferred rendering
	-> important FIRST finish all special algorithms: shadow mapping, normal mapping, transparency, lighting, reflections, MSAA, ... (?)
	-> can be seen as a generic framework to implement BRDFs (?)
		-> sub-surface-scattering
		-> cook torrance sparrow
		-> subsurface scattering
		-> microfacet
	
Post-Processing in Screen-Space
	-> HDR
	-> Bloom
	-> Tone-Mapping
	-> Depth Of Field

Global Illumination Techniques?

Particle System?
	-> CUDA
	-> ... ?
	
Allow Toggle fullscreen
	-> reinit window & render-context!
		=> need to reinig glew, programs, textures,... (?)
		=> lot of work to do, because everything needs to be re-init-able

Optimization WHEN RENDERER HAS FINISHED, NOT BEFORE!!!
	-> pre multiply matrices in CPU instead of doing in shaders
	-> reduce branching in shaders (need different shader-architecture, see below)
	-> Experiment with different render-target formats for performance
	-> really all calls necessary e.g. always bindBuffer, ... ? are some states stored in buffers?
	-> render SKYBOX AFTER other geometry and utilize stencil-buffer to mask fragments occluding the sky-box
	-> Calculate position in Fragment-Shader
		-> http://www.opengl.org/wiki/Compute_eye_space_from_window_space
		-> use screen-coordinates & depth instead of spending a whole buffer on it
		-> compare Performance!!
		From Object-Coordinates to Viewport-Coordinates
		1. Input of object coordinates  aka object-space
				modeling transform
		2. world-coordinates aka world-space
				viewing transform
		3. view-coordinates ( aka eye-coordinates or eye-space)
				projection transform
		4. clip-coordinates ( aka clip-space ): all in range of -/+ clip-volume
				perspective division
		5. normaliced device coordinates ( NDC ): all in range from -1 to +1 (center is 0/0/0 )
				view-port transform
		6. viewport coordinates: all in range from 0/0 to resolutionX/resolutionY of viewport
		7. fragment-shader operates on viewport coordinates
		From Viewport- to View-Space Coordinates
		1. Input of Viewport-Coordinates AND depth in NDC-space for each fragment
				transform x & y to NDC: 
					- divide by resolutionX/resolutionY => range from 0 to 1
					- transform x by: x * 2 - 1 => in range from -1 to 1
					- transform y by: ( 1 - y ) * 2 - 1 => in range from -1 to 1: need to take care of the origin! it makes a difference wheter its in the left UPPER or left LOWER corner
		2. NDC
				add depth to x & y-vector because now all in same space
		3. clip-coordinates
				apply inverse projection transformation to position
				divide by w to transform back to homogenous coordinates
				( in perspective projection the perspective division by w is done => the inverse would be multiplication 
					but we apply the inverse projection transform => need again to divide )
		4. view-coordinates
		
When OpenGL 4.3 Available Switch to
	-> extension ARB_program_interface_query
		
Game-Functionality
	-> allow mutliple scenes which can be changed during runtime. also specify which subsystems are necessary: load/unload them during runtime

Scenes
- brdf & model gallery
	-> famous models with all different brdfs placed in scene like in a gallery
	-> advanced brdfs
	-> shadowing
	-> lighting
	-> find some interesting "skybox" or surrounding model: http://www.3dmodelfree.com/

	Famous models (Stanford http://graphics.stanford.edu/data/3Dscanrep/ & Utah Teapot)
	-> teapot
	-> bunny
	-> dragon
	-> happy buddah
	-> armadillo
	-> lucy
	-> Asian Dragon
	-> Thai Statue

- qualcomm presentation
- chess
	-> show the chess-board 
	-> different material for black & white
	-> board reflects
	-> white transparent
	-> black subsurface scattering brdf
- rotating hyperdrive
	-> point light in center
	-> interesting shadow situation
- physics
	-> mesh
	-> spheres
	-> oder models fall down
	
Multithreading
- make physics processing async

Scripting
- TODO implement during FH-course on computer-languages

Code-Quality
- put magic ids & numbers into constants: uniform-names, uniformblock-names, uniformblock-field names
- const-completeness (add const to inline methods were appropriate)
- replace all strcmp with boost:iequals
- keep id, type & core in ISubSystem as readable
- remove friend-initialisation bullshit from entities
- project buildable as RELEASE
- check if everything is cleaned up when a subsystem cannot be initialized
- A GOOD SOLUTION FOR THE PROBLEM OF INCLUDING TINY-XML IN ALL SUBSYSTEMS
- fmod-subsystem should do a proper loading and managing of its loaded sound (same as e.g. textures in graphics)
- UNIT-Tests?
